{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51de1100",
   "metadata": {},
   "source": [
    "This is the object detection code to detect the waste item in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f53f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Sriram\\Desktop\\Smart-Waste-AI\\model\\glass.jpg: 640x640 1 glass, 141.8ms\n",
      "Speed: 11.7ms preprocess, 141.8ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\Sriram\\runs\\detect\\predict9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model=YOLO(\"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\run\\\\detect\\\\garbage_detection_colab\\\\weights\\\\best.pt\")\n",
    "results=model(\"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\glass.jpg\", save=True)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d3e3b",
   "metadata": {},
   "source": [
    "This will show you the bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6cfaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.2523])\n",
      "data: tensor([[1.3301e+02, 2.6208e+01, 2.2551e+02, 3.2953e+02, 2.5231e-01, 5.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (360, 360)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[179.2649, 177.8682,  92.5000, 303.3207]])\n",
      "xywhn: tensor([[0.4980, 0.4941, 0.2569, 0.8426]])\n",
      "xyxy: tensor([[133.0149,  26.2079, 225.5148, 329.5286]])\n",
      "xyxyn: tensor([[0.3695, 0.0728, 0.6264, 0.9154]])\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "  boxes=result.boxes\n",
    "  print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5601c94",
   "metadata": {},
   "source": [
    "This will give you the segmentation result of your detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, SAM\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO(\"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\run\\\\detect\\\\garbage_detection_colab\\\\weights\\\\best.pt\")\n",
    "\n",
    "# Run detection\n",
    "results = yolo_model(\"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\glass.jpg\")\n",
    "\n",
    "# Load SAM model - use 'cpu' as device\n",
    "sam_model = SAM(\"sam_b.pt\")  # Note: 'sam2_b.pt' might not be the correct name\n",
    "\n",
    "for result in results:\n",
    "    class_ids = result.boxes.cls.int().tolist()\n",
    "    if len(class_ids):\n",
    "        boxes = result.boxes.xyxy\n",
    "        # Run SAM on CPU\n",
    "        sam_results = sam_model(result.orig_img, bboxes=boxes, verbose=False, save=True, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b3908",
   "metadata": {},
   "source": [
    "This is for video segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, SAM\n",
    "import cv2\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO(\"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\run\\\\detect\\\\garbage_detection_colab\\\\weights\\\\best.pt\")\n",
    "\n",
    "# Load SAM model\n",
    "sam_model = SAM(\"sam_b.pt\")\n",
    "\n",
    "# Input video path\n",
    "video_path = \"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\test_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Output video path\n",
    "output_path = \"C:\\\\Users\\\\Sriram\\\\Desktop\\\\Smart-Waste-AI\\\\model\\\\video_segmentation_output(2).mp4\"\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define VideoWriter\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO detection\n",
    "    detect_results = yolo_model(frame)\n",
    "\n",
    "    # Get bounding boxes\n",
    "    boxes = detect_results[0].boxes.xyxy if detect_results[0].boxes else None\n",
    "\n",
    "    if boxes is not None:\n",
    "        # Run SAM segmentation on detected objects\n",
    "        sam_results = sam_model(frame, bboxes=boxes, verbose=False)\n",
    "        # Draw segmentation masks\n",
    "        segmented_frame = sam_results[0].plot()\n",
    "    else:\n",
    "        segmented_frame = frame  # If no detections, keep original frame\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(segmented_frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Segmentation video saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
